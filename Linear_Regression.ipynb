{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets \n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_error(y, X, w):\n",
    "    return ((y - linear_prediction(X, w)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return X.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, w, y):\n",
    "    return (2/y.shape[0]) * (X.T.dot((y - linear_prediction(X, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_stochastic(X, w, y):\n",
    "    return 2 * (X.T.dot((y - linear_prediction(X, w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target, coef = datasets.make_regression(n_features = 2, n_informative = 1, n_targets = 1, \n",
    "                                              noise = 5., coef = True, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.make_regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_desent(X, y, w_init, max_iter, weight_dist, step):\n",
    "    iter_ = 0\n",
    "    w = w_init\n",
    "    weight_dist = np.inf\n",
    "    errors = []\n",
    "    \n",
    "    while (iter_ < max_iter) or (dist > weight_dist):\n",
    "        w_new = w + step * gradient(X, w, y)\n",
    "        dist = np.linalg.norm(w - w_new)\n",
    "        w = w_new\n",
    "        errors.append(mse_error(y, X, w))\n",
    "        iter_ += 1\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_desent(X, y, w_init, max_iter, weight_dist, step):\n",
    "    iter_ = 0\n",
    "    w = w_init\n",
    "    weight_dist = np.inf\n",
    "    errors = []\n",
    "\n",
    "    while (iter_ < max_iter) or (dist > weight_dist):\n",
    "        index = np.random.randint(X.shape[0], size=1)[0]\n",
    "        w_new = w + step * gradient_stochastic(X[index], w, y[index])\n",
    "        dist = np.linalg.norm(w - w_new)\n",
    "        w = w_new\n",
    "        errors.append(mse_error(y[index], X[index], w))\n",
    "        iter_ += 1\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.05 s, sys: 8 ms, total: 4.06 s\n",
      "Wall time: 4.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "batch = gradient_desent(data, target, w_init=[0,0], max_iter=1e5, weight_dist=1e-15, step=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 s, sys: 20 ms, total: 4.54 s\n",
      "Wall time: 4.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stochastic = stochastic_gradient_desent(data, target, w_init=[0,0], max_iter=1e5, weight_dist=1e-15, step=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, alpha=None, regularization=None, max_iter=1e5, weight_dist=1e-15, step=1e-4):\n",
    "        self.regularization = None \n",
    "        self.alpha = None\n",
    "        self.errors = []\n",
    "        self.w = []\n",
    "        self.max_iter = max_iter\n",
    "        self.weight_dist = weight_dist\n",
    "        self.step = step\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "        y = np.array([sum(i*self.w) for i in X])\n",
    "        return y\n",
    "    \n",
    "    def linear_prediction(self, X, w):\n",
    "        return X.dot(w)\n",
    "    \n",
    "    def gradient_stochastic(self, X, w, y):\n",
    "        return 2 * (X.T.dot((y - self.linear_prediction(X, w))))\n",
    "    \n",
    "    \n",
    "    def mse_error(self, y, X, w):\n",
    "        return ((y - self.linear_prediction(X, w)) ** 2).mean()\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "        if self.regularization is None:\n",
    "            self.stochastic_gradient_desent(X, y, np.zeros(X.shape[1]), max_iter=self.max_iter, \\\n",
    "                                            weight_dist=self.weight_dist, step=self.step)\n",
    "        else:\n",
    "            pass\n",
    "#             if regularization is 'lasso':\n",
    "#                 self.stochastic_gradient_desent(X, y, np.zeros(X.shape[1]), max_iter=self.max_iter, \\\n",
    "#                             weight_dist=self.weight_dist, step=self.step)\n",
    "#             else:\n",
    "#                 self.stochastic_gradient_desent(X, y, np.zeros(X.shape[1]), max_iter=self.max_iter, \\\n",
    "#                             weight_dist=self.weight_dist, step=self.step)\n",
    "            \n",
    "    def stochastic_gradient_desent(self, X, y, w_init, max_iter, weight_dist, step):\n",
    "        iter_ = 0\n",
    "        w = w_init\n",
    "        weight_dist = np.inf\n",
    "        errors = []\n",
    "\n",
    "        while (iter_ < max_iter) or (dist > weight_dist):\n",
    "            index = np.random.randint(X.shape[0], size=1)[0]\n",
    "            w_new = w + step * self.gradient_stochastic(X[index], w, y[index])\n",
    "            dist = np.linalg.norm(w - w_new)\n",
    "            w = w_new\n",
    "            errors.append(self.mse_error(y[index], X[index], w))\n",
    "            iter_ += 1\n",
    "            \n",
    "        self.w = w\n",
    "        self.erros = errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
